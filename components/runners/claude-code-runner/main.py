"""
AG-UI Server entry point for Claude Code runner.
Implements the official AG-UI server pattern.
"""
import asyncio
import os
import json
import logging
from contextlib import asynccontextmanager
from typing import Optional, List, Dict, Any, Union

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import uvicorn

from ag_ui.core import RunAgentInput
from ag_ui.encoder import EventEncoder

from context import RunnerContext

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# Flexible input model that matches what our frontend actually sends
class RunnerInput(BaseModel):
    """Input model for runner with optional AG-UI fields."""
    threadId: Optional[str] = None
    thread_id: Optional[str] = None  # Support both camelCase and snake_case
    runId: Optional[str] = None
    run_id: Optional[str] = None
    parentRunId: Optional[str] = None
    parent_run_id: Optional[str] = None
    messages: List[Dict[str, Any]]
    state: Optional[Dict[str, Any]] = None
    tools: Optional[List[Any]] = None
    context: Optional[Union[List[Any], Dict[str, Any]]] = None  # Accept both list and dict, convert to list
    forwardedProps: Optional[Dict[str, Any]] = None
    environment: Optional[Dict[str, str]] = None
    metadata: Optional[Dict[str, Any]] = None
    
    def to_run_agent_input(self) -> RunAgentInput:
        """Convert to official RunAgentInput model."""
        import uuid
        
        # Normalize field names (prefer camelCase for AG-UI)
        thread_id = self.threadId or self.thread_id
        run_id = self.runId or self.run_id
        parent_run_id = self.parentRunId or self.parent_run_id
        
        # Generate runId if not provided
        if not run_id:
            run_id = str(uuid.uuid4())
            logger.info(f"Generated run_id: {run_id}")
        
        # Context should be a list, not a dict
        context_list = self.context if isinstance(self.context, list) else []
        
        return RunAgentInput(
            thread_id=thread_id,
            run_id=run_id,
            parent_run_id=parent_run_id,
            messages=self.messages,
            state=self.state or {},
            tools=self.tools or [],
            context=context_list,
            forwarded_props=self.forwardedProps or {},
        )

# Global context and adapter
context: Optional[RunnerContext] = None
adapter = None  # Will be ClaudeCodeAdapter after initialization


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize and cleanup application resources."""
    global context, adapter
    
    # Import adapter here to avoid circular imports
    from adapter import ClaudeCodeAdapter
    
    # Initialize context from environment
    session_id = os.getenv("SESSION_ID", "unknown")
    workspace_path = os.getenv("WORKSPACE_PATH", "/workspace")
    
    logger.info(f"Initializing AG-UI server for session {session_id}")
    
    context = RunnerContext(
        session_id=session_id,
        workspace_path=workspace_path,
    )
    
    adapter = ClaudeCodeAdapter()
    adapter.context = context
    
    logger.info("Adapter initialized - fresh client will be created for each run")
    
    # Check if this is a resume session via IS_RESUME env var
    # This is set by the operator when restarting a stopped/completed/failed session
    is_resume = os.getenv("IS_RESUME", "").strip().lower() == "true"
    if is_resume:
        logger.info("IS_RESUME=true - this is a resumed session, will skip INITIAL_PROMPT")
    
    # Check for INITIAL_PROMPT and auto-execute (only if not a resume)
    initial_prompt = os.getenv("INITIAL_PROMPT", "").strip()
    if initial_prompt and not is_resume:
        delay = os.getenv("INITIAL_PROMPT_DELAY_SECONDS", "1")
        logger.info(f"INITIAL_PROMPT detected ({len(initial_prompt)} chars), will auto-execute after {delay}s delay")
        asyncio.create_task(auto_execute_initial_prompt(initial_prompt, session_id))
    elif initial_prompt and is_resume:
        logger.info("INITIAL_PROMPT detected but IS_RESUME=true - skipping (this is a resume)")
    
    logger.info(f"AG-UI server ready for session {session_id}")
    
    yield
    
    # Cleanup
    logger.info("Shutting down AG-UI server...")


async def auto_execute_initial_prompt(prompt: str, session_id: str):
    """Auto-execute INITIAL_PROMPT by POSTing to backend after short delay.
    
    The delay gives the runner service time to register in DNS. Backend has retry
    logic to handle if Service DNS isn't ready yet, so this can be short.
    
    Only called for fresh sessions (no hydrated state in .claude/).
    """
    import uuid
    import aiohttp
    
    # Configurable delay (default 1s, was 3s)
    # Backend has retry logic, so we don't need to wait long
    delay_seconds = float(os.getenv("INITIAL_PROMPT_DELAY_SECONDS", "1"))
    logger.info(f"Waiting {delay_seconds}s before auto-executing INITIAL_PROMPT (allow Service DNS to propagate)...")
    await asyncio.sleep(delay_seconds)
    
    logger.info("Auto-executing INITIAL_PROMPT via backend POST...")
    
    # Get backend URL from environment
    backend_url = os.getenv("BACKEND_API_URL", "").rstrip("/")
    project_name = os.getenv("PROJECT_NAME", "").strip() or os.getenv("AGENTIC_SESSION_NAMESPACE", "").strip()
    
    if not backend_url or not project_name:
        logger.error("Cannot auto-execute INITIAL_PROMPT: BACKEND_API_URL or PROJECT_NAME not set")
        return
    
    # BACKEND_API_URL already includes /api suffix from operator
    url = f"{backend_url}/projects/{project_name}/agentic-sessions/{session_id}/agui/run"
    logger.info(f"Auto-execution URL: {url}")
    
    payload = {
        "threadId": session_id,
        "runId": str(uuid.uuid4()),
        "messages": [{
            "id": str(uuid.uuid4()),
            "role": "user",
            "content": prompt,
            "metadata": {
                "hidden": True,
                "autoSent": True,
                "source": "runner_initial_prompt"
            }
        }]
    }
    
    # Get BOT_TOKEN for auth
    bot_token = os.getenv("BOT_TOKEN", "").strip()
    headers = {"Content-Type": "application/json"}
    if bot_token:
        headers["Authorization"] = f"Bearer {bot_token}"
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=payload, headers=headers, timeout=aiohttp.ClientTimeout(total=30)) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    logger.info(f"INITIAL_PROMPT auto-execution started: {result}")
                else:
                    error_text = await resp.text()
                    logger.warning(f"INITIAL_PROMPT failed with status {resp.status}: {error_text[:200]}")
    except Exception as e:
        logger.warning(f"INITIAL_PROMPT auto-execution error (backend will retry): {e}")



app = FastAPI(
    title="Claude Code AG-UI Server",
    version="0.2.0",
    lifespan=lifespan
)


# Track if adapter has been initialized
_adapter_initialized = False


@app.post("/")
async def run_agent(input_data: RunnerInput, request: Request):
    """
    AG-UI compatible run endpoint.
    
    Accepts flexible input with thread_id, run_id, messages.
    Optional fields: state, tools, context, forwardedProps.
    Returns SSE stream of AG-UI events.
    """
    global _adapter_initialized
    
    if not adapter:
        raise HTTPException(status_code=503, detail="Adapter not initialized")
    
    # Convert to official RunAgentInput
    run_agent_input = input_data.to_run_agent_input()
    
    # Get Accept header for encoder
    accept_header = request.headers.get("accept", "text/event-stream")
    encoder = EventEncoder(accept=accept_header)
    
    logger.info(f"Processing run: thread_id={run_agent_input.thread_id}, run_id={run_agent_input.run_id}")
    
    async def event_generator():
        """Generate AG-UI events from adapter."""
        global _adapter_initialized
        
        try:
            logger.info("Event generator started")
            
            # Initialize adapter on first run
            if not _adapter_initialized:
                logger.info("First run - initializing adapter with workspace preparation")
                await adapter.initialize(context)
                logger.info("Adapter initialization complete")
                _adapter_initialized = True
            
            logger.info("Starting adapter.process_run()...")
            
            # Process the run (creates fresh client each time)
            async for event in adapter.process_run(run_agent_input):
                logger.debug(f"Yielding run event: {event.type}")
                yield encoder.encode(event)
            logger.info("adapter.process_run() completed")
        except Exception as e:
            logger.error(f"Error in event generator: {e}")
            # Yield error event
            from ag_ui.core import RunErrorEvent, EventType
            error_event = RunErrorEvent(
                type=EventType.RUN_ERROR,
                thread_id=run_agent_input.thread_id or context.session_id,
                run_id=run_agent_input.run_id or "unknown",
                message=str(e)
            )
            yield encoder.encode(error_event)
    
    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type(),
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
        }
    )


@app.post("/interrupt")
async def interrupt_run():
    """
    Interrupt the current Claude SDK execution.
    
    Sends interrupt signal to Claude subprocess to stop mid-execution.
    See: https://platform.claude.com/docs/en/agent-sdk/python#methods
    """
    if not adapter:
        raise HTTPException(status_code=503, detail="Adapter not initialized")
    
    logger.info("Interrupt request received")
    
    try:
        # Call adapter's interrupt method which signals the active Claude SDK client
        await adapter.interrupt()
        
        return {"message": "Interrupt signal sent to Claude SDK"}
    except Exception as e:
        logger.error(f"Interrupt failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


async def clone_workflow_at_runtime(git_url: str, branch: str, subpath: str) -> tuple[bool, str]:
    """
    Clone a workflow repository at runtime.
    
    This mirrors the logic in hydrate.sh but runs when workflows are changed
    after the pod has started.
    
    Returns:
        (success, workflow_dir_path) tuple
    """
    import tempfile
    import shutil
    from pathlib import Path
    
    if not git_url:
        return False, ""
    
    # Derive workflow name from URL
    workflow_name = git_url.split("/")[-1].removesuffix(".git")
    workspace_path = os.getenv("WORKSPACE_PATH", "/workspace")
    workflow_final = Path(workspace_path) / "workflows" / workflow_name
    
    logger.info(f"Cloning workflow '{workflow_name}' from {git_url}@{branch}")
    if subpath:
        logger.info(f"  Subpath: {subpath}")
    
    # Create temp directory for clone
    temp_dir = Path(tempfile.mkdtemp(prefix="workflow-clone-"))
    
    try:
        # Build git clone command with optional auth token
        github_token = os.getenv("GITHUB_TOKEN", "").strip()
        gitlab_token = os.getenv("GITLAB_TOKEN", "").strip()
        
        # Determine which token to use based on URL
        clone_url = git_url
        if github_token and "github" in git_url.lower():
            clone_url = git_url.replace("https://", f"https://x-access-token:{github_token}@")
            logger.info("Using GITHUB_TOKEN for workflow authentication")
        elif gitlab_token and "gitlab" in git_url.lower():
            clone_url = git_url.replace("https://", f"https://oauth2:{gitlab_token}@")
            logger.info("Using GITLAB_TOKEN for workflow authentication")
        
        # Clone the repository
        process = await asyncio.create_subprocess_exec(
            "git", "clone", "--branch", branch, "--single-branch", "--depth", "1",
            clone_url, str(temp_dir),
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            # Redact tokens from error message
            error_msg = stderr.decode()
            if github_token:
                error_msg = error_msg.replace(github_token, "***REDACTED***")
            if gitlab_token:
                error_msg = error_msg.replace(gitlab_token, "***REDACTED***")
            logger.error(f"Failed to clone workflow: {error_msg}")
            return False, ""
        
        logger.info("Clone successful, processing...")
        
        # Handle subpath extraction
        if subpath:
            subpath_full = temp_dir / subpath
            if subpath_full.exists() and subpath_full.is_dir():
                logger.info(f"Extracting subpath: {subpath}")
                # Remove existing workflow dir if exists
                if workflow_final.exists():
                    shutil.rmtree(workflow_final)
                # Create parent dirs and copy subpath
                workflow_final.parent.mkdir(parents=True, exist_ok=True)
                shutil.copytree(subpath_full, workflow_final)
                logger.info(f"Workflow extracted to {workflow_final}")
            else:
                logger.warning(f"Subpath '{subpath}' not found, using entire repo")
                if workflow_final.exists():
                    shutil.rmtree(workflow_final)
                shutil.move(str(temp_dir), str(workflow_final))
        else:
            # No subpath - use entire repo
            if workflow_final.exists():
                shutil.rmtree(workflow_final)
            shutil.move(str(temp_dir), str(workflow_final))
        
        logger.info(f"Workflow '{workflow_name}' ready at {workflow_final}")
        return True, str(workflow_final)
        
    except Exception as e:
        logger.error(f"Error cloning workflow: {e}")
        return False, ""
    finally:
        # Cleanup temp directory if it still exists
        if temp_dir.exists():
            shutil.rmtree(temp_dir, ignore_errors=True)


@app.post("/workflow")
async def change_workflow(request: Request):
    """
    Change active workflow - triggers Claude SDK client restart and new greeting.
    
    Accepts: {"gitUrl": "...", "branch": "...", "path": "..."}
    """
    global _adapter_initialized
    
    if not adapter:
        raise HTTPException(status_code=503, detail="Adapter not initialized")
    
    body = await request.json()
    git_url = body.get("gitUrl", "")
    branch = body.get("branch", "main")
    path = body.get("path", "")
    
    logger.info(f"Workflow change request: {git_url}@{branch} (path: {path})")
    
    # Clone the workflow repository at runtime
    # This is needed because the init container only runs once at pod startup
    if git_url:
        success, workflow_path = await clone_workflow_at_runtime(git_url, branch, path)
        if not success:
            logger.warning("Failed to clone workflow, will use default workflow directory")
    
    # Update environment variables
    os.environ["ACTIVE_WORKFLOW_GIT_URL"] = git_url
    os.environ["ACTIVE_WORKFLOW_BRANCH"] = branch
    os.environ["ACTIVE_WORKFLOW_PATH"] = path
    
    # Reset adapter state to force reinitialization on next run
    _adapter_initialized = False
    adapter._first_run = True
    
    logger.info("Workflow updated, adapter will reinitialize on next run")
    
    # Trigger a new run to greet user with workflow context
    # This runs in background via backend POST
    asyncio.create_task(trigger_workflow_greeting(git_url, branch, path))
    
    return {"message": "Workflow updated", "gitUrl": git_url, "branch": branch, "path": path}


async def clone_repo_at_runtime(git_url: str, branch: str, name: str) -> tuple[bool, str]:
    """
    Clone a repository at runtime.
    
    This mirrors the logic in hydrate.sh but runs when repos are added
    after the pod has started.
    
    Args:
        git_url: Git repository URL
        branch: Branch to clone
        name: Name for the cloned directory (derived from URL if empty)
    
    Returns:
        (success, repo_dir_path) tuple
    """
    import tempfile
    import shutil
    from pathlib import Path
    
    if not git_url:
        return False, ""
    
    # Derive repo name from URL if not provided
    if not name:
        name = git_url.split("/")[-1].removesuffix(".git")
    
    # Repos are stored in /workspace/repos/{name} (matching hydrate.sh)
    workspace_path = os.getenv("WORKSPACE_PATH", "/workspace")
    repos_dir = Path(workspace_path) / "repos"
    repos_dir.mkdir(parents=True, exist_ok=True)
    repo_final = repos_dir / name
    
    logger.info(f"Cloning repo '{name}' from {git_url}@{branch}")
    
    # Skip if already cloned
    if repo_final.exists():
        logger.info(f"Repo '{name}' already exists at {repo_final}, skipping clone")
        return True, str(repo_final)
    
    # Create temp directory for clone
    temp_dir = Path(tempfile.mkdtemp(prefix="repo-clone-"))
    
    try:
        # Build git clone command with optional auth token
        github_token = os.getenv("GITHUB_TOKEN", "").strip()
        gitlab_token = os.getenv("GITLAB_TOKEN", "").strip()
        
        # Determine which token to use based on URL
        clone_url = git_url
        if github_token and "github" in git_url.lower():
            # Add GitHub token to URL
            clone_url = git_url.replace("https://", f"https://x-access-token:{github_token}@")
            logger.info("Using GITHUB_TOKEN for authentication")
        elif gitlab_token and "gitlab" in git_url.lower():
            # Add GitLab token to URL
            clone_url = git_url.replace("https://", f"https://oauth2:{gitlab_token}@")
            logger.info("Using GITLAB_TOKEN for authentication")
        
        # Clone the repository
        process = await asyncio.create_subprocess_exec(
            "git", "clone", "--branch", branch, "--single-branch", "--depth", "1",
            clone_url, str(temp_dir),
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            # Redact tokens from error message
            error_msg = stderr.decode()
            if github_token:
                error_msg = error_msg.replace(github_token, "***REDACTED***")
            if gitlab_token:
                error_msg = error_msg.replace(gitlab_token, "***REDACTED***")
            logger.error(f"Failed to clone repo: {error_msg}")
            return False, ""
        
        logger.info("Clone successful, moving to final location...")
        
        # Move to final location
        repo_final.parent.mkdir(parents=True, exist_ok=True)
        shutil.move(str(temp_dir), str(repo_final))
        
        logger.info(f"Repo '{name}' ready at {repo_final}")
        return True, str(repo_final)
        
    except Exception as e:
        logger.error(f"Error cloning repo: {e}")
        return False, ""
    finally:
        # Cleanup temp directory if it still exists
        if temp_dir.exists():
            shutil.rmtree(temp_dir, ignore_errors=True)


async def trigger_workflow_greeting(git_url: str, branch: str, path: str):
    """Trigger workflow greeting after workflow change."""
    import uuid
    import aiohttp
    
    # Wait a moment for workflow to be cloned/initialized
    await asyncio.sleep(3)
    
    logger.info("Triggering workflow greeting...")
    
    try:
        backend_url = os.getenv("BACKEND_API_URL", "").rstrip("/")
        project_name = os.getenv("AGENTIC_SESSION_NAMESPACE", "").strip()
        session_id = context.session_id if context else "unknown"
        
        if not backend_url or not project_name:
            logger.error("Cannot trigger workflow greeting: BACKEND_API_URL or PROJECT_NAME not set")
            return
        
        url = f"{backend_url}/projects/{project_name}/agentic-sessions/{session_id}/agui/run"
        
        # Extract workflow name for greeting
        workflow_name = git_url.split("/")[-1].removesuffix(".git")
        if path:
            workflow_name = path.split("/")[-1]
        
        greeting = f"Greet the user and explain that the {workflow_name} workflow is now active. Briefly describe what this workflow helps with based on the systemPrompt in ambient.json. Keep it concise and friendly."
        
        payload = {
            "threadId": session_id,
            "runId": str(uuid.uuid4()),
            "messages": [{
                "id": str(uuid.uuid4()),
                "role": "user",
                "content": greeting,
                "metadata": {
                    "hidden": True,
                    "autoSent": True,
                    "source": "workflow_activation"
                }
            }]
        }
        
        bot_token = os.getenv("BOT_TOKEN", "").strip()
        headers = {"Content-Type": "application/json"}
        if bot_token:
            headers["Authorization"] = f"Bearer {bot_token}"
        
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=payload, headers=headers) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    logger.info(f"Workflow greeting started: {result}")
                else:
                    error_text = await resp.text()
                    logger.error(f"Workflow greeting failed: {resp.status} - {error_text}")
    
    except Exception as e:
        logger.error(f"Failed to trigger workflow greeting: {e}")


@app.post("/repos/add")
async def add_repo(request: Request):
    """
    Add repository - clones repo and triggers Claude SDK client restart.
    
    Accepts: {"url": "...", "branch": "...", "name": "..."}
    """
    global _adapter_initialized
    
    if not adapter:
        raise HTTPException(status_code=503, detail="Adapter not initialized")
    
    body = await request.json()
    url = body.get("url", "")
    branch = body.get("branch", "main")
    name = body.get("name", "")
    
    logger.info(f"Add repo request: url={url}, branch={branch}, name={name}")
    
    if not url:
        raise HTTPException(status_code=400, detail="Repository URL is required")
    
    # Derive name from URL if not provided
    if not name:
        name = url.split("/")[-1].removesuffix(".git")
    
    # Clone the repository at runtime
    success, repo_path = await clone_repo_at_runtime(url, branch, name)
    if not success:
        raise HTTPException(status_code=500, detail=f"Failed to clone repository: {url}")
    
    # Update REPOS_JSON env var
    repos_json = os.getenv("REPOS_JSON", "[]")
    try:
        repos = json.loads(repos_json) if repos_json else []
    except:
        repos = []
    
    # Add new repo
    repos.append({
        "name": name,
        "input": {
            "url": url,
            "branch": branch
        }
    })
    
    os.environ["REPOS_JSON"] = json.dumps(repos)
    
    # Reset adapter state to force reinitialization on next run
    _adapter_initialized = False
    adapter._first_run = True
    
    logger.info(f"Repo '{name}' added and cloned, adapter will reinitialize on next run")
    
    # Trigger a notification to Claude about the new repository
    asyncio.create_task(trigger_repo_added_notification(name, url))
    
    return {"message": "Repository added", "name": name, "path": repo_path}


async def trigger_repo_added_notification(repo_name: str, repo_url: str):
    """Notify Claude that a repository has been added."""
    import uuid
    import aiohttp
    
    # Wait a moment for repo to be fully ready
    await asyncio.sleep(1)
    
    logger.info(f"Triggering repo added notification for: {repo_name}")
    
    try:
        backend_url = os.getenv("BACKEND_API_URL", "").rstrip("/")
        project_name = os.getenv("AGENTIC_SESSION_NAMESPACE", "").strip()
        session_id = context.session_id if context else "unknown"
        
        if not backend_url or not project_name:
            logger.error("Cannot trigger repo notification: BACKEND_API_URL or PROJECT_NAME not set")
            return
        
        url = f"{backend_url}/projects/{project_name}/agentic-sessions/{session_id}/agui/run"
        
        notification = f"The repository '{repo_name}' has been added to your workspace. You can now access it at the path 'repos/{repo_name}/'. Please acknowledge this to the user and let them know you can now read and work with files in this repository."
        
        payload = {
            "threadId": session_id,
            "runId": str(uuid.uuid4()),
            "messages": [{
                "id": str(uuid.uuid4()),
                "role": "user",
                "content": notification,
                "metadata": {
                    "hidden": True,
                    "autoSent": True,
                    "source": "repo_added"
                }
            }]
        }
        
        bot_token = os.getenv("BOT_TOKEN", "").strip()
        headers = {"Content-Type": "application/json"}
        if bot_token:
            headers["Authorization"] = f"Bearer {bot_token}"
        
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=payload, headers=headers) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    logger.info(f"Repo notification sent: {result}")
                else:
                    error_text = await resp.text()
                    logger.error(f"Repo notification failed: {resp.status} - {error_text}")
    
    except Exception as e:
        logger.error(f"Failed to trigger repo notification: {e}")


@app.post("/repos/remove")
async def remove_repo(request: Request):
    """
    Remove repository - triggers Claude SDK client restart.
    
    Accepts: {"name": "..."}
    """
    global _adapter_initialized
    
    if not adapter:
        raise HTTPException(status_code=503, detail="Adapter not initialized")
    
    body = await request.json()
    repo_name = body.get("name", "")
    logger.info(f"Remove repo request: {repo_name}")
    
    # Update REPOS_JSON env var
    repos_json = os.getenv("REPOS_JSON", "[]")
    try:
        repos = json.loads(repos_json) if repos_json else []
    except:
        repos = []
    
    # Remove repo by name
    repos = [r for r in repos if r.get("name") != repo_name]
    
    os.environ["REPOS_JSON"] = json.dumps(repos)
    
    # Reset adapter state
    _adapter_initialized = False
    adapter._first_run = True
    
    logger.info(f"Repo removed, adapter will reinitialize on next run")
    
    return {"message": "Repository removed"}


@app.get("/health")
async def health():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "session_id": context.session_id if context else None,
    }


def main():
    """Start the AG-UI server."""
    port = int(os.getenv("AGUI_PORT", "8000"))
    host = os.getenv("AGUI_HOST", "0.0.0.0")
    
    logger.info(f"Starting Claude Code AG-UI server on {host}:{port}")
    
    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="info",
    )


if __name__ == "__main__":
    main()

